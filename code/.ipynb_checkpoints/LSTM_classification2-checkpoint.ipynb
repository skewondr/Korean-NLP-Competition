{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <=distance,  >=round"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "#train + evaluation set 합쳐진 상태. \n",
    "df = pd.read_pickle(\"../data/train/train_ids2.pkl\")\n",
    "test_df = pd.read_pickle(\"../data/test/test_ids2.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>123</th>\n",
       "      <th>124</th>\n",
       "      <th>125</th>\n",
       "      <th>126</th>\n",
       "      <th>127</th>\n",
       "      <th>128</th>\n",
       "      <th>129</th>\n",
       "      <th>130</th>\n",
       "      <th>131</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20.0</td>\n",
       "      <td>4841.0</td>\n",
       "      <td>2664.0</td>\n",
       "      <td>3273.0</td>\n",
       "      <td>3724.0</td>\n",
       "      <td>1217.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2027.0</td>\n",
       "      <td>2979.0</td>\n",
       "      <td>3158.0</td>\n",
       "      <td>12749.0</td>\n",
       "      <td>674.0</td>\n",
       "      <td>257.0</td>\n",
       "      <td>16925.0</td>\n",
       "      <td>3435.0</td>\n",
       "      <td>2827.0</td>\n",
       "      <td>4532.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16.0</td>\n",
       "      <td>435.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1195.0</td>\n",
       "      <td>6266.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>15206.0</td>\n",
       "      <td>12466.0</td>\n",
       "      <td>1308.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25695.0</td>\n",
       "      <td>2154.0</td>\n",
       "      <td>10327.0</td>\n",
       "      <td>751.0</td>\n",
       "      <td>4795.0</td>\n",
       "      <td>325.0</td>\n",
       "      <td>1643.0</td>\n",
       "      <td>28244.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>292.0</td>\n",
       "      <td>2559.0</td>\n",
       "      <td>1214.0</td>\n",
       "      <td>231.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5066.0</td>\n",
       "      <td>373.0</td>\n",
       "      <td>5647.0</td>\n",
       "      <td>3435.0</td>\n",
       "      <td>27921.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144309</th>\n",
       "      <td>1070.0</td>\n",
       "      <td>5965.0</td>\n",
       "      <td>173.0</td>\n",
       "      <td>2789.0</td>\n",
       "      <td>5573.0</td>\n",
       "      <td>2789.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>334.0</td>\n",
       "      <td>5931.0</td>\n",
       "      <td>5573.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144310</th>\n",
       "      <td>819.0</td>\n",
       "      <td>2824.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>407.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>792.0</td>\n",
       "      <td>3624.0</td>\n",
       "      <td>1431.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144311</th>\n",
       "      <td>140.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>3500.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>8094.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>17111.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144312</th>\n",
       "      <td>4434.0</td>\n",
       "      <td>674.0</td>\n",
       "      <td>20381.0</td>\n",
       "      <td>298.0</td>\n",
       "      <td>2270.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>11016.0</td>\n",
       "      <td>13020.0</td>\n",
       "      <td>199.0</td>\n",
       "      <td>6389.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144313</th>\n",
       "      <td>3500.0</td>\n",
       "      <td>674.0</td>\n",
       "      <td>23591.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>405.0</td>\n",
       "      <td>842.0</td>\n",
       "      <td>2181.0</td>\n",
       "      <td>9032.0</td>\n",
       "      <td>674.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>144314 rows × 133 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0       1        2        3       4       5        6        7  \\\n",
       "0          20.0  4841.0   2664.0   3273.0  3724.0  1217.0      NaN      NaN   \n",
       "1        2027.0  2979.0   3158.0  12749.0   674.0   257.0  16925.0   3435.0   \n",
       "2          16.0   435.0      0.0   1195.0  6266.0   150.0  15206.0  12466.0   \n",
       "3       25695.0  2154.0  10327.0    751.0  4795.0   325.0   1643.0  28244.0   \n",
       "4         292.0  2559.0   1214.0    231.0    10.0  5066.0    373.0   5647.0   \n",
       "...         ...     ...      ...      ...     ...     ...      ...      ...   \n",
       "144309   1070.0  5965.0    173.0   2789.0  5573.0  2789.0     94.0    334.0   \n",
       "144310    819.0  2824.0     14.0    407.0     7.0   792.0   3624.0   1431.0   \n",
       "144311    140.0   120.0     25.0   3500.0    12.0    48.0     62.0   8094.0   \n",
       "144312   4434.0   674.0  20381.0    298.0  2270.0    49.0  11016.0  13020.0   \n",
       "144313   3500.0   674.0  23591.0     37.0   405.0   842.0   2181.0   9032.0   \n",
       "\n",
       "             8        9  ...  123  124  125  126  127  128  129  130  131  \\\n",
       "0          NaN      NaN  ...  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "1       2827.0   4532.0  ...  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "2       1308.0      NaN  ...  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "3          NaN      NaN  ...  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "4       3435.0  27921.0  ...  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "...        ...      ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "144309  5931.0   5573.0  ...  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "144310     NaN      NaN  ...  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "144311    11.0  17111.0  ...  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "144312   199.0   6389.0  ...  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "144313   674.0      NaN  ...  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "\n",
       "        Label  \n",
       "0           0  \n",
       "1           1  \n",
       "2           0  \n",
       "3           0  \n",
       "4           1  \n",
       "...       ...  \n",
       "144309      1  \n",
       "144310      0  \n",
       "144311      0  \n",
       "144312      1  \n",
       "144313      0  \n",
       "\n",
       "[144314 rows x 133 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124314\n",
      "104314\n"
     ]
    }
   ],
   "source": [
    "seed = 100\n",
    "train_df = df.copy()\n",
    "df0=df.loc[(df['Label']==0)].sample(n = 20000, random_state = seed) \n",
    "train_df = train_df.drop(df0.index)\n",
    "print(len(train_df))\n",
    "df1=df.loc[(df['Label']==1)].sample(n = 20000, random_state = seed) \n",
    "train_df = train_df.drop(df1.index)\n",
    "print(len(train_df))\n",
    "\n",
    "train_df.reset_index(drop=True, inplace=True)\n",
    "eval_df = pd.DataFrame()\n",
    "eval_df = df0.append(df1)\n",
    "eval_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def countLabel(data):\n",
    "    count0 = 0\n",
    "    count1 = 0\n",
    "    for label in data:\n",
    "        if label == 0: \n",
    "            count0+=1\n",
    "        elif label == 1: \n",
    "            count1+=1\n",
    "    total = len(data)\n",
    "    print(\"총 데이터 개수:\", total)\n",
    "    print(\"class 0 개수: %d, 비율: %.2f\"%(count0, count0/total))\n",
    "    print(\"class 1 개수: %d, 비율: %.2f\"%(count1, count1/total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 데이터 개수: 104314\n",
      "class 0 개수: 52434, 비율: 0.50\n",
      "class 1 개수: 51880, 비율: 0.50\n",
      "총 데이터 개수: 40000\n",
      "class 0 개수: 20000, 비율: 0.50\n",
      "class 1 개수: 20000, 비율: 0.50\n",
      "총 데이터 개수: 50000\n",
      "class 0 개수: 24827, 비율: 0.50\n",
      "class 1 개수: 25173, 비율: 0.50\n"
     ]
    }
   ],
   "source": [
    "countLabel(train_df['Label'])\n",
    "countLabel(eval_df['Label'])\n",
    "countLabel(test_df['Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_truncating(data, max_len):\n",
    "    for num in range(len(data) - max_len):\n",
    "        data.pop(0)\n",
    "    return data\n",
    "\n",
    "def pre_padding(data, max_len, padding_value):\n",
    "    for num in range(max_len - len(data)):\n",
    "        data.insert(0, padding_value)\n",
    "    return data\n",
    "    \n",
    "# def post_padding():\n",
    "# def pre_truncating():\n",
    "    \n",
    "def pad(df, max_len, padding, padding_value):\n",
    "    X = df.values.tolist()\n",
    "    X_ = []\n",
    "    for index, ids in enumerate(X):\n",
    "        X_.append([int(i) for i in ids if str(i) != 'nan'])\n",
    "    \n",
    "    #padding \n",
    "    if padding == 'pre':\n",
    "        pad=[]\n",
    "        for ids in X_:\n",
    "            if len(ids) < max_len:\n",
    "                p = pre_padding(ids, max_len, padding_value)\n",
    "            elif len(ids) > max_len:\n",
    "                p = pre_truncating(ids, max_len)\n",
    "            else : \n",
    "                p = ids\n",
    "            pad.append(p)\n",
    "      \n",
    "#     if padding == 'post':\n",
    "        \n",
    "    return np.array(pad) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 40\n",
    "train_pad = pad(train_df.iloc[:,:-1], max_len, \"pre\", 0)\n",
    "eval_pad = pad(eval_df.iloc[:,:-1], max_len, \"pre\", 0)\n",
    "test_pad = pad(test_df.iloc[:,:-1], max_len, \"pre\", 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104314 104314\n",
      "40000 40000\n",
      "50000 50000\n"
     ]
    }
   ],
   "source": [
    "print(len(train_df),len(train_pad))\n",
    "print(len(eval_df),len(eval_pad))\n",
    "print(len(test_df),len(test_pad))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.datasets import reuters\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense, LSTM, Embedding, Dropout\n",
    "from tensorflow.python.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.python.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.python.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sentencepiece as spm\n",
    "sp = spm.SentencePieceProcessor()\n",
    "\n",
    "model_name = 'm_30.model'\n",
    "vocab_name = 'm_30.vocab'\n",
    "sp.load('./sp_models/'+ model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "1044/1044 [==============================] - 84s 80ms/step - loss: 0.4334 - acc: 0.7944 - val_loss: 0.3863 - val_acc: 0.8271\n",
      "Epoch 2/200\n",
      "1044/1044 [==============================] - 84s 80ms/step - loss: 0.3401 - acc: 0.8516 - val_loss: 0.3757 - val_acc: 0.8310\n",
      "Epoch 3/200\n",
      "1044/1044 [==============================] - 83s 80ms/step - loss: 0.2912 - acc: 0.8746 - val_loss: 0.3845 - val_acc: 0.8311\n",
      "Epoch 4/200\n",
      "1044/1044 [==============================] - 93s 89ms/step - loss: 0.2496 - acc: 0.8943 - val_loss: 0.4145 - val_acc: 0.8297\n",
      "Epoch 5/200\n",
      "1044/1044 [==============================] - 84s 81ms/step - loss: 0.2120 - acc: 0.9126 - val_loss: 0.4647 - val_acc: 0.8241\n",
      "Epoch 6/200\n",
      "1044/1044 [==============================] - 84s 80ms/step - loss: 0.1805 - acc: 0.9264 - val_loss: 0.4958 - val_acc: 0.8184\n",
      "Epoch 7/200\n",
      "1044/1044 [==============================] - 84s 80ms/step - loss: 0.1536 - acc: 0.9400 - val_loss: 0.5951 - val_acc: 0.8169\n",
      "WARNING:tensorflow:From <ipython-input-12-d43b56a627b8>:37: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n"
     ]
    }
   ],
   "source": [
    "#version: class-weight 적용 안함 \n",
    "from tensorflow import keras\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.python.keras.models import load_model\n",
    "from keras.utils.np_utils import to_categorical\n",
    "#from sklearn.model_selection import StratifiedKFold\n",
    "#kfold=StratifiedKFold(n_splits=10, shuffle=True, random_state=1)\n",
    "#cvscores=[]\n",
    "num_words=30000\n",
    "hidden = 100\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=0, patience=5)\n",
    "mc = ModelCheckpoint('lstm_model_2.h5', monitor='val_acc',mode='max', \n",
    "                     verbose=0, save_best_only=True)\n",
    "\n",
    "with tf.device('/CPU:0'):\n",
    "        \n",
    "    model = Sequential()\n",
    "    #Embedding(number of samples(단어 사전 크기), hidden layer size)\n",
    "    model.add(Embedding(num_words, hidden))\n",
    "    model.add(LSTM(hidden, return_sequences=True))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(LSTM(hidden, return_sequences=True))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(LSTM(hidden))\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "#     lr_schedule = keras.optimizers.schedules.ExponentialDecay(initial_learning_rate=3e-3, \n",
    "#                                                               decay_steps=10000, decay_rate=0.85)\n",
    "#     opt = keras.optimizers.Adam(learning_rate=lr_schedule)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=\"adam\", metrics=['acc'])\n",
    "    history = model.fit(train_pad, to_categorical(train_df['Label'], num_classes=2), batch_size=100, epochs=200, \n",
    "                        verbose=1, callbacks=[es, mc], \n",
    "                        validation_data=(eval_pad,to_categorical(eval_df['Label'], num_classes=2)))\n",
    "    predict_num = model.predict_classes(eval_pad)\n",
    "    file_name='./result/check_cases/predict_wrong2.tsv'\n",
    "    caseBoard = pd.DataFrame()\n",
    "    for i, real in enumerate(eval_df['Label']):\n",
    "        if(real != predict_num[i]):\n",
    "            myList = [round(x) for x in train_pad[i].tolist()]\n",
    "            line = re.sub('⁇','',sp.decode_ids(myList))\n",
    "            newDict = {'real': str(real), 'predict':str(predict_num[i]), 'text':line}\n",
    "            caseBoard = caseBoard.append(newDict, ignore_index = True)\n",
    "    caseBoard.to_csv( file_name, index=False, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.82784\n",
      "[[20508  4319]\n",
      " [ 4289 20884]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.83      0.83     24827\n",
      "           1       0.83      0.83      0.83     25173\n",
      "\n",
      "    accuracy                           0.83     50000\n",
      "   macro avg       0.83      0.83      0.83     50000\n",
      "weighted avg       0.83      0.83      0.83     50000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#load model and evaluate \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "with tf.device('/CPU:0'):\n",
    "    re_model = load_model('lstm_model_2.h5')\n",
    "#     re_model.fit(train_pad.iloc[:,:-1], to_categorical(train_pad['label'], num_classes=3))\n",
    "    y_pred1 = re_model.predict_classes(test_pad)\n",
    "\n",
    "target_names=['0', '1']\n",
    "print(\"Accuracy:\", metrics.accuracy_score(test_df['Label'], y_pred1))\n",
    "print(confusion_matrix(test_df['Label'], y_pred1))\n",
    "print(classification_report(test_df['Label'], y_pred1, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yoonjin/anaconda3/envs/medinfo/lib/python3.7/site-packages/ipykernel_launcher.py:8: MatplotlibDeprecationWarning: savefig() got unexpected keyword argument \"box_inches\" which is no longer supported as of 3.3 and will become an error two minor releases later\n",
      "  \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sn\n",
    "data_= {'y_Actual':test_df['Label'], 'y_Predicted': y_pred1}\n",
    "df_cm = pd.DataFrame(data_, columns=['y_Actual','y_Predicted'])\n",
    "confusion_matrix = pd.crosstab(df_cm['y_Actual'], df_cm['y_Predicted'],\n",
    "                               rownames=['Actual'], colnames=['Predicted'])\n",
    "\n",
    "sn.heatmap(confusion_matrix, annot=True, fmt='d', cmap='YlGnBu')\n",
    "plt.savefig('./result/check_cases/distance.png', box_inches='tight')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "medinfo",
   "language": "python",
   "name": "medinfo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
