{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#---목표---#\n",
    "1. 형태소 단위의 토큰화 (komoran / wordpiece) 비교하기 \n",
    "    * 형태소로 하는 이유 : 안다, 안한다, 안에 (동사, 부사, 명사 구분) \n",
    "2. oov의 경우, 가까운 음운으로 변환해주는 코드 개발 \n",
    "    * 100개 (최대) corpus 설정 후 그 안에서 hyter parameter 설정에 따라 비슷한 단어를 같은 인덱스로 묶는 경우 \n",
    "    * 100개 (최대) corpus 설정 후 임베딩 과정에서 oov가 발생할 경우, 가장 비슷한 단어를 같은 인덱스로 붙여주는 경우 (임베딩 time complexity가 굉장히 늘어남) \n",
    "3. 임베딩: padding, 형태소, 문장, 단어 \n",
    "4. 위와 같이 새로운 임베딩 방식을 기반으로 한 kobert pre-training & fine-tuning\n",
    "5. train 할때는 masked sentence까지 포함한다. \n",
    "6. nsmc + 국립국어원 웹 corpus 데이터 이용 \n",
    "    '모두의 말뭉치'에서 웹 말뭉치, 형태 분석 말뭉치를 사용한다.  \n",
    "7. 웹말뭉치 + nsmc train 으로 단어 사전 생성 및 pre-train 해보기 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nsmc_EDA\n",
    "#---전처리 과정---#\n",
    "1. 특수문자, 이모티콘, 숫자, 공백 (일단 숫자와 공백만 제거하기) \n",
    "2. 토큰화 (패키지에 따라 형태소 구분 방식이 다르기 때문에 앙상블을 이용해보자..) \n",
    "3. 불용어, 표제어 제거 (한국어에서는 불용어를 따로 지정하는 것이 좋음. 품사에 따라 지정해보자!) \n",
    "\n",
    "#---시각화 과정---#\n",
    "1. 클래스 개수 비율 분포 v\n",
    "2. 한 문장 당 사용 단어 수 v\n",
    "3. 전체 데이터 내에서 단어 빈도수 v\n",
    "4. 토큰화 후 임베딩 시 UNK 토큰의 수 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import csv\n",
    "import os\n",
    "import logging\n",
    "import argparse\n",
    "import random\n",
    "from tqdm import tqdm, trange\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "\n",
    "from transformers import BertTokenizer\n",
    "from transformers import BertForSequenceClassification\n",
    "#from transformers import BertAdam\n",
    "from transformers.optimization import AdamW, get_linear_schedule_with_warmup\n",
    "\n",
    "from transformers import PYTORCH_PRETRAINED_BERT_CACHE\n",
    "\n",
    "logging.basicConfig(format = '%(asctime)s - %(levelname)s - %(name)s -   %(message)s',\n",
    "                    datefmt = '%m/%d/%Y %H:%M:%S',\n",
    "                    level = logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InputExample(object):\n",
    "    \"\"\"A single training/test example for simple sequence classification.\"\"\"\n",
    "\n",
    "    def __init__(self, guid, text_a, text_b=None, label=None):\n",
    "        \"\"\"Constructs a InputExample.\n",
    "        sample 하나 당 하나의 InputExample. 다음과 같은 argument가 전달 됨.  \n",
    "            guid: 하나의 example에 대한 고유 번호.\n",
    "            text_a: 토큰화 하기 전 첫번째 문장\n",
    "            text_b: 토큰화 하기 전 두번째 문장\n",
    "            label: (문자열) example의 라벨. \n",
    "        Args:\n",
    "            guid: Unique id for the example.\n",
    "            text_a: string. The untokenized text of the first sequence. For single\n",
    "            sequence tasks, only this sequence must be specified.\n",
    "            text_b: (Optional) string. The untokenized text of the second sequence.\n",
    "            Only must be specified for sequence pair tasks.\n",
    "            label: (Optional) string. The label of the example. This should be\n",
    "            specified for train and dev examples, but not for test examples.\n",
    "        \"\"\"\n",
    "        self.guid = guid\n",
    "        self.text_a = text_a\n",
    "        self.text_b = text_b\n",
    "        self.label = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataProcessor(object):\n",
    "    \"\"\"Base class for data converters for sequence classification data sets.\"\"\"\n",
    "\n",
    "    def get_train_examples(self, data_dir):\n",
    "        \"\"\"Gets a collection of `InputExample`s for the train set.\"\"\"\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def get_dev_examples(self, data_dir):\n",
    "        \"\"\"Gets a collection of `InputExample`s for the dev set.\"\"\"\n",
    "        raise NotImplementedError()\n",
    "        \n",
    "    def get_test_examples(self, data_dir):\n",
    "        \"\"\"Gets a collection of `InputExample`s for the dev set.\"\"\"\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def get_labels(self):\n",
    "        \"\"\"Gets the list of labels for this data set.\"\"\"\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    @classmethod\n",
    "    def _read_txt(cls, input_file, quotechar=None):\n",
    "        \"\"\"Reads a tab separated value file.\n",
    "            파일에서 한 줄 씩 읽어 lines 리스트에 저장합니다. \n",
    "        \"\"\"\n",
    "        with open(input_file, \"r\", encoding='utf-8') as f:\n",
    "            reader = csv.reader(f, delimiter=\"\\t\", quotechar=quotechar)\n",
    "            lines = []\n",
    "            for line in reader:\n",
    "                #print(line)\n",
    "                lines.append(line)\n",
    "            return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"nsmc 데이터를 처리하는 nsmcProcessor\"\"\"\n",
    "\n",
    "class nsmcProcessor(DataProcessor):\n",
    "    \"\"\"Processor for the nsmc data set (Naver sentiment movie corpus v1.0).\"\"\"\n",
    "\n",
    "    def get_train_examples(self, data_dir):\n",
    "        \"\"\"See base class.\"\"\"\n",
    "        logger.info(\"LOOKING AT {}\".format(os.path.join(data_dir, \"ratings_train.txt\")))\n",
    "        return self._create_examples(\n",
    "            self._read_txt(os.path.join(data_dir, \"ratings_train.txt\")), \"train\")\n",
    "\n",
    "    def get_dev_examples(self, data_dir):\n",
    "        \"\"\"See base class.\"\"\"\n",
    "        return self._create_examples(\n",
    "            self._read_txt(os.path.join(data_dir, \"ratings_dev.txt\")), \"dev\")\n",
    "    \n",
    "    def get_test_examples(self, data_dir):\n",
    "        \"\"\"See base class.\"\"\"\n",
    "        return self._create_examples(\n",
    "            self._read_txt(os.path.join(data_dir, \"ratings_test.txt\")), \"test\")\n",
    "\n",
    "    def get_labels(self):\n",
    "        \"\"\"See base class.\"\"\"\n",
    "        return [\"0\", \"1\"] # 부정 0 긍정 1\n",
    "\n",
    "    def _create_examples(self, lines, set_type):\n",
    "        \"\"\"Creates examples for the training and dev sets.\n",
    "           각 줄에서 guid, text_a, text_b, label을 추출하여 InputExample을 통해 데이터 재정렬.    \n",
    "        \"\"\"\n",
    "        examples = []\n",
    "        for (i, line) in enumerate(lines):\n",
    "            if i==0: \n",
    "                continue\n",
    "            guid = \"%s-%s\" % (set_type, i) #train/dev + index \n",
    "            text_a = line[1]\n",
    "            text_b = None\n",
    "            label = int(line[2])\n",
    "            #print(\"text_a: \", text_a, \"label:\", label)\n",
    "            examples.append(\n",
    "                InputExample(guid=guid, text_a=text_a, text_b=text_b, label=label))\n",
    "        return examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"모두의 말뭉치 웹 말뭉치 데이터를 처리하는 webmProcessor\"\"\"\n",
    "\n",
    "class webmProcessor(DataProcessor):\n",
    "    \"\"\"Processor for the \"web malmoongchi\" data set\"\"\"\n",
    "\n",
    "    def get_train_examples(self, data_dir):\n",
    "        \"\"\"See base class.\"\"\"\n",
    "        logger.info(\"LOOKING AT {}\".format(os.path.join(data_dir, \"ratings_train.txt\")))\n",
    "        return self._create_examples(\n",
    "            self._read_txt(os.path.join(data_dir, \"ratings_train.txt\")), \"train\")\n",
    "\n",
    "    def get_dev_examples(self, data_dir):\n",
    "        \"\"\"See base class.\"\"\"\n",
    "        return self._create_examples(\n",
    "            self._read_txt(os.path.join(data_dir, \"ratings_dev.txt\")), \"dev\")\n",
    "    \n",
    "    def get_test_examples(self, data_dir):\n",
    "        \"\"\"See base class.\"\"\"\n",
    "        return self._create_examples(\n",
    "            self._read_txt(os.path.join(data_dir, \"ratings_test.txt\")), \"test\")\n",
    "\n",
    "    def get_labels(self):\n",
    "        \"\"\"See base class.\"\"\"\n",
    "        return [\"0\", \"1\"] # 부정 0 긍정 1\n",
    "\n",
    "    def _create_examples(self, lines, set_type):\n",
    "        \"\"\"Creates examples for the training and dev sets.\n",
    "           각 줄에서 guid, text_a, text_b, label을 추출하여 InputExample을 통해 데이터 재정렬.    \n",
    "        \"\"\"\n",
    "        examples = []\n",
    "        for (i, line) in enumerate(lines):\n",
    "            if i==0: \n",
    "                continue\n",
    "            guid = \"%s-%s\" % (set_type, i) #train/dev + index \n",
    "            text_a = line[1]\n",
    "            text_b = None\n",
    "            label = int(line[2])\n",
    "            #print(\"text_a: \", text_a, \"label:\", label)\n",
    "            examples.append(\n",
    "                InputExample(guid=guid, text_a=text_a, text_b=text_b, label=label))\n",
    "        return examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "09/04/2020 20:08:21 - INFO - __main__ -   LOOKING AT ../data/ratings_train.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\ttext \n",
      "     0  아 더빙.. 진짜 짜증나네요 목소리                                                                                  \n",
      "     1  흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나                                                                    \n",
      "     0  너무재밓었다그래서보는것을추천한다                                                                                    \n",
      "     0  교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정                                                                        \n",
      "     1  사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 던스트가 너무나도 이뻐보였다                                        \n"
     ]
    }
   ],
   "source": [
    "data_dir = \"../data/\"\n",
    "\n",
    "# 데이터 불러오기 위한 개체 생성 \n",
    "processor = nsmcProcessor()\n",
    "# train data 불러오기 \n",
    "train_examples = processor.get_train_examples(data_dir)\n",
    "\n",
    "print(\"{:2} \".format(\"label\\ttext\"))\n",
    "for (ex_index, example) in enumerate(train_examples):\n",
    "    if ex_index < 5:\n",
    "        print(\"{:6} \".format(example.label), end=' ')\n",
    "        print(\"{:<100} \".format(example.text_a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 데이터 개수: 150000\n",
      "class 0 개수: 75173, 비율: 0.50\n",
      "class 1 개수: 74827, 비율: 0.50\n"
     ]
    }
   ],
   "source": [
    "#클래스 개수 비율 분포 \n",
    "def countLabel(data):\n",
    "    count0 = 0\n",
    "    count1 = 0\n",
    "    for (ex_index, example) in enumerate(data):\n",
    "        if example.label == 0: \n",
    "            count0+=1\n",
    "        elif example.label == 1: \n",
    "            count1+=1\n",
    "    total = len(data)\n",
    "    print(\"총 데이터 개수:\", total)\n",
    "    print(\"class 0 개수: %d, 비율: %.2f\"%(count0, count0/total))\n",
    "    print(\"class 1 개수: %d, 비율: %.2f\"%(count1, count1/total))\n",
    "countLabel(train_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#대략적인 vocab size 정하기 \n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "#단어 빈도수 \n",
    "def show_word_counts(t, data):\n",
    "    t.fit_on_texts(data)\n",
    "    count=t.word_counts\n",
    "    print(len(count))\n",
    "\n",
    "    sorted_count=sorted(count.items(), key=lambda item: item[1], reverse=True)\n",
    "    word_data=pd.DataFrame(sorted_count)\n",
    "    word_data= word_data.rename(columns={0: \"key\", 1:\"value\"})\n",
    "    \n",
    "    print(word_data)\n",
    "    return word_data\n",
    "\n",
    "#단어 빈도수 분포 \n",
    "def show_counts_frequency(word_data):\n",
    "    length=len(word_data)\n",
    "    list1=[] #count. 단어의 빈도수 list\n",
    "    list2=[] #frequency. 단어의 빈도수의 빈도수 list\n",
    "    index=0\n",
    "    for i in range(length): \n",
    "        cnt=0 #단어의 빈도수의 빈도수 \n",
    "        while length-index-1>=0 and i+1==word_data['value'][length-index-1]:\n",
    "            cnt+=1\n",
    "            #print(y2_l-index-1,y2[y2_l-index-1],cnt)\n",
    "            index+=1\n",
    "        if(cnt!=0):\n",
    "            list1.append(i+1)\n",
    "            list2.append(cnt) \n",
    "            \n",
    "    word_count = pd.DataFrame(list(zip(list1, list2)), \n",
    "                   columns =['count', 'frequency']) \n",
    "    print(word_count[:100])\n",
    "\n",
    "    total=0\n",
    "    for i in range(100):\n",
    "        total+=word_count['frequency'][i]\n",
    "    print(\"1번~100번 등장한 단어의 총 빈도수:\", total,\n",
    "          \"전체 단어 대비 1번~100번 등장한 단어(비율):\",'{:.2f}'.format(total/length*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "296310\n",
      "           key  value\n",
      "0           영화  18995\n",
      "1           너무   8563\n",
      "2           정말   8537\n",
      "3           진짜   6682\n",
      "4            이   5418\n",
      "...        ...    ...\n",
      "296305     더블은      1\n",
      "296306    뭔죄인가      1\n",
      "296307  거들먹거리고      1\n",
      "296308     혼혈은      1\n",
      "296309    수간하는      1\n",
      "\n",
      "[296310 rows x 2 columns]\n",
      "    count  frequency\n",
      "0       1     224179\n",
      "1       2      28976\n",
      "2       3      11675\n",
      "3       4       6536\n",
      "4       5       4279\n",
      "..    ...        ...\n",
      "95     96         12\n",
      "96     97         14\n",
      "97     98         15\n",
      "98     99          9\n",
      "99    100          7\n",
      "\n",
      "[100 rows x 2 columns]\n",
      "1번~100번 등장한 단어의 총 빈도수: 295073 전체 단어 대비 1번~100번 등장한 단어(비율): 99.58\n"
     ]
    }
   ],
   "source": [
    "X=[]\n",
    "for (ex_index, example) in enumerate(train_examples):\n",
    "    X.append(example.text_a)\n",
    "\n",
    "t= Tokenizer(lower=True, oov_token=True)\n",
    "\n",
    "word_data = show_word_counts(t, X)\n",
    "show_counts_frequency(word_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing.text import text_to_word_sequence\n",
    "\n",
    "def show_token_count(data):\n",
    "    data_=[]\n",
    "    for line in data:\n",
    "        line2=text_to_word_sequence(line) \n",
    "        data_.append(line2)\n",
    "        \n",
    "    len_result = [len(s) for s in data_]\n",
    "\n",
    "    plt.clf() #clear previous figure\n",
    "    plt.hist(len_result,bins=100)\n",
    "    plt.title('Distribution of length')\n",
    "    plt.xlabel('length')\n",
    "    plt.ylabel('number')\n",
    "    plt.savefig('words_distrib.png', bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "    print('example의 최대 사용 단어 수 : {}'.format(np.max(len_result)))\n",
    "    print('example의 평균 사용 단어 수 : {:.2f}'.format(np.mean(len_result)))\n",
    "    print('example의 중앙값 사용 단어 수: {:.2f}'.format(np.median(len_result)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "example의 최대 사용 단어 수 : 59\n",
      "example의 평균 사용 단어 수 : 7.85\n",
      "example의 중앙값 사용 단어 수: 6.00\n"
     ]
    }
   ],
   "source": [
    "show_token_count(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "세계환경수도 조성위해 10개년 실천계획 만들겠다\n",
      "['세계', '환경', '수도', '조성', '위하', '아', '10', '개년', '실천', '계획', '만들', '겠', '다']\n",
      "[('세계', 'NNG'), ('환경', 'NNP'), ('수도', 'NNP'), ('조성', 'NNG'), ('위하', 'VV'), ('아', 'EC'), ('10', 'SN'), ('개년', 'NNB'), ('실천', 'NNG'), ('계획', 'NNG'), ('만들', 'VV'), ('겠', 'EP'), ('다', 'EC')]\n",
      "\n",
      "아버지가방에들어가신다\n",
      "['아버지', '가방', '에', '들어가', '시', 'ㄴ다']\n",
      "[('아버지', 'NNG'), ('가방', 'NNP'), ('에', 'JKB'), ('들어가', 'VV'), ('시', 'EP'), ('ㄴ다', 'EC')]\n",
      "\n",
      "걍 너무 너무 싶퍼요퓨ㅠㅠ 민검사님.걍 쩔고요 아.. 말고안나옵니다\n",
      "['걍', '너무', '너무', '싶퍼요퓨ㅠㅠ', '민검사님.걍', '쩌', 'ㄹ', '고요', '아', '.', '.', '말', '고안', '나오', 'ㅂ니다']\n",
      "[('걍', 'NA'), ('너무', 'MAG'), ('너무', 'MAG'), ('싶퍼요퓨ㅠㅠ', 'NA'), ('민검사님.걍', 'NA'), ('쩌', 'EF'), ('ㄹ', 'ETM'), ('고요', 'NNP'), ('아', 'IC'), ('.', 'SF'), ('.', 'SF'), ('말', 'NNG'), ('고안', 'NNP'), ('나오', 'VV'), ('ㅂ니다', 'EC')]\n"
     ]
    }
   ],
   "source": [
    "#토큰화 (komoran / sentencepiece) 비교\n",
    "#komoran\n",
    "import konlpy\n",
    "from konlpy.tag import Komoran \n",
    "komoran = Komoran()\n",
    "\n",
    "# komoran은 빈줄이 있으면 에러가 남\n",
    "#komoran.morphs(\"\\n\".join([s for s in c[:40].split(\"\\n\") if s]))\n",
    "\n",
    "#21세기 세종계획의 품사기준을 따르고 있다. \n",
    "print('세계환경수도 조성위해 10개년 실천계획 만들겠다')\n",
    "print(komoran.morphs(u'세계환경수도 조성위해 10개년 실천계획 만들겠다'))\n",
    "print(komoran.pos(u'세계환경수도 조성위해 10개년 실천계획 만들겠다'))\n",
    "print()\n",
    "print('아버지가방에들어가신다')\n",
    "print(komoran.morphs(u'아버지가방에들어가신다'))\n",
    "print(komoran.pos(u'아버지가방에들어가신다'))\n",
    "print()\n",
    "print('걍 너무 너무 싶퍼요퓨ㅠㅠ 민검사님.걍 쩔고요 아.. 말고안나옵니다')\n",
    "print(komoran.morphs(u'걍 너무 너무 싶퍼요퓨ㅠㅠ 민검사님.걍 쩔고요 아.. 말고안나옵니다'))\n",
    "print(komoran.pos(u'걍 너무 너무 싶퍼요퓨ㅠㅠ 민검사님.걍 쩔고요 아.. 말고안나옵니다'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('걍', 'NA'), ('너무', 'MAG'), ('너무', 'MAG'), ('싶', 'NA'), ('푸', 'VV'), ('어', 'EC'), ('요퓨ᅲᅲ', 'NA'), ('민', 'NNP'), ('검사', 'NNG'), ('님', 'XSN'), ('.', 'SF'), ('걍', 'NA'), ('쩌', 'EF'), ('ㄹ', 'ETM'), ('고', 'NNP'), ('요', 'MM'), ('아', 'IC'), ('..', 'SE'), ('말', 'VX'), ('고', 'EC'), ('안', 'MAG'), ('나오', 'VV'), ('ㅂ니다', 'EC')]\n"
     ]
    }
   ],
   "source": [
    "print([('걍', 'NA'), ('너무', 'MAG'), ('너무', 'MAG'), ('싶', 'NA'), ('푸', 'VV'), ('어', 'EC'), ('요퓨ᅲᅲ', 'NA'), ('민', 'NNP'), ('검사', 'NNG'), ('님', 'XSN'), ('.', 'SF'), ('걍', 'NA'), ('쩌', 'EF'), ('ㄹ', 'ETM'), ('고', 'NNP'), ('요', 'MM'), ('아', 'IC'), ('..', 'SE'), ('말', 'VX'), ('고', 'EC'), ('안', 'MAG'), ('나오', 'VV'), ('ㅂ니다', 'EC')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sentencepiece\n",
    "import sentencepiece as spm\n",
    "\n",
    "# #nsmc txt 파일 생성하기 \n",
    "# with open('../data/nsmc.txt', 'a') as f:\n",
    "#     for s in X:\n",
    "#         f.write(\"%s\\n\" % s)\n",
    "\n",
    "spm.SentencePieceTrainer.train('--input=../data/ratings_train.txt --model_prefix=nsmc_m --vocab_size=144652')\n",
    "sp = spm.SentencePieceProcessor()\n",
    "sp.load('nsmc_m.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from django.contrib.admin.utils import flatten\n",
    "\n",
    "def convert_pos(pieces):\n",
    "    komoran = Komoran()\n",
    "    output=[]\n",
    "    for p in pieces:\n",
    "        p = re.sub('▁','',p)\n",
    "        pos = komoran.pos(p)\n",
    "        output.append(pos)\n",
    "    return flatten(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "세계환경수도 조성위해 10개년 실천계획 만들겠다\n",
      "['▁세계', '환경', '수도', '▁조성', '위해', '▁10', '개', '년', '▁실천', '계', '획', '▁만들겠다']\n",
      "[('세계', 'NNG'), ('환경', 'NNG'), ('수', 'NNB'), ('도', 'JX'), ('조성', 'NNG'), ('위하', 'VV'), ('아', 'EC'), ('10', 'SN'), ('개', 'NNB'), ('년', 'NNB'), ('실천', 'NNG'), ('계', 'NNG'), ('획', 'MAG'), ('만들', 'VV'), ('겠', 'EP'), ('다', 'EC')]\n",
      "\n",
      "아버지가방에들어가신다\n",
      "['▁아버지가', '방에', '들어가', '신다']\n",
      "[('아버지', 'NNG'), ('가', 'JKS'), ('방', 'NNG'), ('에', 'JKB'), ('들어가', 'VV'), ('아', 'EC'), ('신', 'VV'), ('다', 'EC')]\n",
      "\n",
      "걍 너무 너무 싶퍼요퓨ㅠㅠ 민검사님.걍 쩔고요 아.. 말고안나옵니다\n",
      "['▁걍', '▁너무', '▁너무', '▁싶', '퍼', '요퓨ᅲᅲ', '▁민검사님', '.', '걍', '▁쩔고', '요', '▁아', '..', '▁말고', '안나옵니다']\n",
      "[('걍', 'NA'), ('너무', 'MAG'), ('너무', 'MAG'), ('싶', 'NA'), ('푸', 'VV'), ('어', 'EC'), ('요퓨ᅲᅲ', 'NA'), ('민', 'NNP'), ('검사', 'NNG'), ('님', 'XSN'), ('.', 'SF'), ('걍', 'NA'), ('쩌', 'EF'), ('ㄹ', 'ETM'), ('고', 'NNP'), ('요', 'MM'), ('아', 'IC'), ('..', 'SE'), ('말', 'VX'), ('고', 'EC'), ('안', 'MAG'), ('나오', 'VV'), ('ㅂ니다', 'EC')]\n"
     ]
    }
   ],
   "source": [
    "#Komoran을 한번 거치는 과정에서 sentencepiece으로 토큰화된 토큰이 더 세부적으로 쪼개지게 됨\n",
    "#그러면서 품사 태깅을 더 정확하게 하는 효과가 있음!\n",
    "#정돈된 문장은 komoran, 비문은 sentencepiece가 더 강한 느낌이다. \n",
    "\n",
    "print('세계환경수도 조성위해 10개년 실천계획 만들겠다')\n",
    "print(sp.encode_as_pieces('세계환경수도 조성위해 10개년 실천계획 만들겠다'))\n",
    "print(convert_pos(sp.encode_as_pieces('세계환경수도 조성위해 10개년 실천계획 만들겠다')))\n",
    "\n",
    "print()\n",
    "print('아버지가방에들어가신다')\n",
    "print(sp.encode_as_pieces('아버지가방에들어가신다'))\n",
    "print(convert_pos(sp.encode_as_pieces('아버지가방에들어가신다')))\n",
    "\n",
    "print()\n",
    "print('걍 너무 너무 싶퍼요퓨ㅠㅠ 민검사님.걍 쩔고요 아.. 말고안나옵니다')\n",
    "print(sp.encode_as_pieces('걍 너무 너무 싶퍼요퓨ㅠㅠ 민검사님.걍 쩔고요 아.. 말고안나옵니다'))\n",
    "print(convert_pos(sp.encode_as_pieces('걍 너무 너무 싶퍼요퓨ㅠㅠ 민검사님.걍 쩔고요 아.. 말고안나옵니다')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "medinfo",
   "language": "python",
   "name": "medinfo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
